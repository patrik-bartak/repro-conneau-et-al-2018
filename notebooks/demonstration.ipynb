{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Results demo for Natural Language Inference (NLI)\n",
    "\n",
    "In order to investigate the trained models, we use this notebook to load the final trained checkpoint of the BiLSTM with max pooling (the best performing model) and perform inference with a few examples. "
   ],
   "id": "4211f31737ff22e0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T16:58:03.652846Z",
     "start_time": "2024-04-22T16:58:03.624480Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "32ed8fb5be6adbd8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T16:58:03.674374Z",
     "start_time": "2024-04-22T16:58:03.653942Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import os.path\n",
    "from spacy.lang.en import English\n",
    "import torch.nn.functional as F\n",
    "from src.models.nliclassifier import NLIClassifier\n",
    "from src.dataset.dataloaders import get_embeddings_for_data\n",
    "from src.dataset.snli_dataset import str_to_idxs, label_map"
   ],
   "id": "b3b703e8d7cd040",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We start by getting the vocabulary and embeddings vectors that were used to train the models. The following function will attempt to read them in if they are located in `/data/processed`. ",
   "id": "91d217518e9d13a2"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-22T16:58:09.519168Z",
     "start_time": "2024-04-22T16:58:03.675091Z"
    }
   },
   "source": [
    "# Make sure to enter the parent dir of the embedding vocab+vector file used for training\n",
    "emb_vocab, emb_vecs = get_embeddings_for_data(\n",
    "    dataset_path=os.path.join(\"..\", \"data\", \"processed\")\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We then load the final model checkpoint for the BiLSTMMaxPool. There may be an error that the `embedding.weight` is missing from the checkpoint, but this was done simply to reduce the size of the checkpoints. We set `strict=False` and provide the embedding vectors to the model init function through the kwargs of the `load_from_checkpoint` function.",
   "id": "ae90c41902091a9d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T16:58:09.599215Z",
     "start_time": "2024-04-22T16:58:09.520271Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the model along with the embeddings\n",
    "model = (\n",
    "    NLIClassifier.load_from_checkpoint(\n",
    "        os.path.join(\n",
    "            \"..\",\n",
    "            \"checkpoint\",\n",
    "            \"real_blstmpme_train\",\n",
    "            \"final.ckpt\",\n",
    "        ),\n",
    "        strict=False,\n",
    "        embedding_mat=emb_vecs,\n",
    "    )\n",
    "    .cpu()\n",
    "    .eval()\n",
    ")"
   ],
   "id": "b7f11ded35cbbfca",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We use the same tokenizer that was used to train the model. ",
   "id": "ebfe4552fa9c4c33"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T16:58:09.670210Z",
     "start_time": "2024-04-22T16:58:09.600084Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer = English().tokenizer",
   "id": "8ac9279ade079438",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This function processes the string input, passes it through the model, computes the label, and prints out the final model judgement. ",
   "id": "c9deac9d8ba88f9d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T16:58:09.688481Z",
     "start_time": "2024-04-22T16:58:09.671083Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def predict_and_print(sent_1, sent_2):\n",
    "    inps_1, len_1 = str_to_idxs(sent_1, tokenizer, emb_vocab)\n",
    "    inps_2, len_2 = str_to_idxs(sent_2, tokenizer, emb_vocab)\n",
    "    out = model(inps_1, inps_2, len_1, len_2)\n",
    "    probs = F.softmax(out, dim=-1)\n",
    "    label = torch.argmax(probs, dim=1).unsqueeze(0).detach().item()\n",
    "    print(\n",
    "        f\"\"\"\n",
    "    Premise: \"{sent_1}\"\n",
    "    Hypothesis: \"{sent_2}\"\n",
    "    Model judgement: \"{label_map[label]}\"\n",
    "    \"\"\"\n",
    "    )"
   ],
   "id": "3c84f50d804ebecb",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T16:58:09.718460Z",
     "start_time": "2024-04-22T16:58:09.689207Z"
    }
   },
   "cell_type": "code",
   "source": "predict_and_print(\"Two men sitting in the sun\", \"Nobody is sitting in the shade\")",
   "id": "a56f478cc4580582",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Premise: \"Two men sitting in the sun\"\n",
      "    Hypothesis: \"Nobody is sitting in the shade\"\n",
      "    Model judgement: \"contradiction\"\n",
      "    \n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T16:58:09.745063Z",
     "start_time": "2024-04-22T16:58:09.719413Z"
    }
   },
   "cell_type": "code",
   "source": "predict_and_print(\"A man is walking a dog\", \"No cat is outside\")",
   "id": "ec314d988a41805a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Premise: \"A man is walking a dog\"\n",
      "    Hypothesis: \"No cat is outside\"\n",
      "    Model judgement: \"contradiction\"\n",
      "    \n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Results analysis\n",
    "\n",
    "The examples above are judged as contradictions by the model even though they should be judged as neutral. We can speculate a few reasons why this happens."
   ],
   "id": "ba4400d39d10a95f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "595953d7939fb8f9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
