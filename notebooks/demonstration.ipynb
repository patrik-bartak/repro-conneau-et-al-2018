{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Results demo for Natural Language Inference (NLI)\n",
    "\n",
    "In order to investigate the trained models, we use this notebook to load the final trained checkpoint of the BiLSTM with max pooling (the best performing model) and perform inference with a few examples. "
   ],
   "id": "4211f31737ff22e0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T20:52:00.017665Z",
     "start_time": "2024-04-22T20:51:59.877232Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "32ed8fb5be6adbd8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T20:52:00.749476Z",
     "start_time": "2024-04-22T20:52:00.723494Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import os.path\n",
    "from spacy.lang.en import English\n",
    "import torch.nn.functional as F\n",
    "from src.models.nliclassifier import NLIClassifier\n",
    "from src.dataset.dataloaders import get_embeddings_for_data\n",
    "from src.dataset.snli_dataset import str_to_idxs, label_map"
   ],
   "id": "b3b703e8d7cd040",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We start by getting the vocabulary and embeddings vectors that were used to train the models. The following function will attempt to read them in if they are located in `/data/processed`. ",
   "id": "91d217518e9d13a2"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-22T20:55:16.640880Z",
     "start_time": "2024-04-22T20:52:02.399746Z"
    }
   },
   "source": [
    "# Make sure to enter the parent dir of the embedding vocab+vector file used for training\n",
    "emb_vocab, emb_vecs = get_embeddings_for_data(\n",
    "    dataset_path=os.path.join(\"..\", \"data\", \"processed\")\n",
    ")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/9824 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d670e3f00b684973b2ff7410c762e535"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/9842 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a105b7d13cbe4552b155bcb31b3f60d3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/549367 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e95360e5903b4983b2d4df13fee2b6f3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/9824 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "16dd998a18e7479b9f5e2d012ec9bb0d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/9842 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "713236b7528f4fdd99fc76af7f86bc1e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/549367 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "851a315c9c9a4405a9732e943d84382f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache/glove.840B.300d.zip:  11%|â–ˆ         | 235M/2.18G [02:33<21:11, 1.53MB/s]     \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[27], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Make sure to enter the parent dir of the embedding vocab+vector file used for training\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m emb_vocab, emb_vecs \u001B[38;5;241m=\u001B[39m \u001B[43mget_embeddings_for_data\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdataset_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m..\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdata\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mprocessed\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/code/patrik-bartak/learning-sentence-representations/src/dataset/dataloaders.py:38\u001B[0m, in \u001B[0;36mget_embeddings_for_data\u001B[0;34m(dataset_path)\u001B[0m\n\u001B[1;32m     36\u001B[0m os\u001B[38;5;241m.\u001B[39mmakedirs(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mdirname(embedding_path), exist_ok\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     37\u001B[0m tokens \u001B[38;5;241m=\u001B[39m get_unique_tokens(data)\n\u001B[0;32m---> 38\u001B[0m emb_vocab, emb_vecs \u001B[38;5;241m=\u001B[39m \u001B[43mget_aligned_glove_embeddings_from_unique_tokens\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtokens\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     39\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(embedding_path, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwb\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[1;32m     40\u001B[0m     pickle\u001B[38;5;241m.\u001B[39mdump((emb_vocab, emb_vecs), f)\n",
      "File \u001B[0;32m~/code/patrik-bartak/learning-sentence-representations/src/dataset/snli_dataset.py:65\u001B[0m, in \u001B[0;36mget_aligned_glove_embeddings_from_unique_tokens\u001B[0;34m(tokens)\u001B[0m\n\u001B[1;32m     62\u001B[0m custom_vocab\u001B[38;5;241m.\u001B[39mset_default_index(\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m     63\u001B[0m logging\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCreated custom vocab of size \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(custom_vocab\u001B[38;5;241m.\u001B[39mget_itos())\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 65\u001B[0m glove_embeddings \u001B[38;5;241m=\u001B[39m \u001B[43mGloVe\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m840B\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m300\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m logging\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLoaded GloVe embeddings of size \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(glove_embeddings)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     67\u001B[0m \u001B[38;5;66;03m# Get only the ones we need\u001B[39;00m\n\u001B[1;32m     68\u001B[0m \u001B[38;5;66;03m# glove_embeddings.get_vecs_by_tokens(custom_vocab.get_itos())\u001B[39;00m\n",
      "File \u001B[0;32m~/miniforge3/envs/atcs/lib/python3.10/site-packages/torchtext/vocab/vectors.py:223\u001B[0m, in \u001B[0;36mGloVe.__init__\u001B[0;34m(self, name, dim, **kwargs)\u001B[0m\n\u001B[1;32m    221\u001B[0m url \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39murl[name]\n\u001B[1;32m    222\u001B[0m name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mglove.\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124md.txt\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(name, \u001B[38;5;28mstr\u001B[39m(dim))\n\u001B[0;32m--> 223\u001B[0m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mGloVe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniforge3/envs/atcs/lib/python3.10/site-packages/torchtext/vocab/vectors.py:59\u001B[0m, in \u001B[0;36mVectors.__init__\u001B[0;34m(self, name, cache, url, unk_init, max_vectors)\u001B[0m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdim \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     58\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39munk_init \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mTensor\u001B[38;5;241m.\u001B[39mzero_ \u001B[38;5;28;01mif\u001B[39;00m unk_init \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m unk_init\n\u001B[0;32m---> 59\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcache\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcache\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_vectors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_vectors\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniforge3/envs/atcs/lib/python3.10/site-packages/torchtext/vocab/vectors.py:101\u001B[0m, in \u001B[0;36mVectors.cache\u001B[0;34m(self, name, cache, url, max_vectors)\u001B[0m\n\u001B[1;32m     99\u001B[0m         \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# remove the partial zip file\u001B[39;00m\n\u001B[1;32m    100\u001B[0m             os\u001B[38;5;241m.\u001B[39mremove(dest)\n\u001B[0;32m--> 101\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[1;32m    102\u001B[0m logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExtracting vectors into \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(cache))\n\u001B[1;32m    103\u001B[0m ext \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39msplitext(dest)[\u001B[38;5;241m1\u001B[39m][\u001B[38;5;241m1\u001B[39m:]\n",
      "File \u001B[0;32m~/miniforge3/envs/atcs/lib/python3.10/site-packages/torchtext/vocab/vectors.py:98\u001B[0m, in \u001B[0;36mVectors.cache\u001B[0;34m(self, name, cache, url, max_vectors)\u001B[0m\n\u001B[1;32m     96\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tqdm(unit\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mB\u001B[39m\u001B[38;5;124m\"\u001B[39m, unit_scale\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, miniters\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, desc\u001B[38;5;241m=\u001B[39mdest) \u001B[38;5;28;01mas\u001B[39;00m t:\n\u001B[1;32m     97\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 98\u001B[0m         \u001B[43murlretrieve\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreporthook\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreporthook\u001B[49m\u001B[43m(\u001B[49m\u001B[43mt\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     99\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# remove the partial zip file\u001B[39;00m\n\u001B[1;32m    100\u001B[0m         os\u001B[38;5;241m.\u001B[39mremove(dest)\n",
      "File \u001B[0;32m~/miniforge3/envs/atcs/lib/python3.10/urllib/request.py:270\u001B[0m, in \u001B[0;36murlretrieve\u001B[0;34m(url, filename, reporthook, data)\u001B[0m\n\u001B[1;32m    267\u001B[0m     reporthook(blocknum, bs, size)\n\u001B[1;32m    269\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 270\u001B[0m     block \u001B[38;5;241m=\u001B[39m \u001B[43mfp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    271\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m block:\n\u001B[1;32m    272\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[0;32m~/miniforge3/envs/atcs/lib/python3.10/http/client.py:464\u001B[0m, in \u001B[0;36mHTTPResponse.read\u001B[0;34m(self, amt)\u001B[0m\n\u001B[1;32m    461\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlength \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m amt \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlength:\n\u001B[1;32m    462\u001B[0m     \u001B[38;5;66;03m# clip the read to the \"end of response\"\u001B[39;00m\n\u001B[1;32m    463\u001B[0m     amt \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlength\n\u001B[0;32m--> 464\u001B[0m s \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mamt\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    465\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m s \u001B[38;5;129;01mand\u001B[39;00m amt:\n\u001B[1;32m    466\u001B[0m     \u001B[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001B[39;00m\n\u001B[1;32m    467\u001B[0m     \u001B[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001B[39;00m\n\u001B[1;32m    468\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_close_conn()\n",
      "File \u001B[0;32m~/miniforge3/envs/atcs/lib/python3.10/socket.py:705\u001B[0m, in \u001B[0;36mSocketIO.readinto\u001B[0;34m(self, b)\u001B[0m\n\u001B[1;32m    703\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m    704\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 705\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecv_into\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    706\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m timeout:\n\u001B[1;32m    707\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_timeout_occurred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m~/miniforge3/envs/atcs/lib/python3.10/ssl.py:1273\u001B[0m, in \u001B[0;36mSSLSocket.recv_into\u001B[0;34m(self, buffer, nbytes, flags)\u001B[0m\n\u001B[1;32m   1269\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m flags \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m   1270\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1271\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m\n\u001B[1;32m   1272\u001B[0m           \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m)\n\u001B[0;32m-> 1273\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnbytes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1274\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1275\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001B[0;32m~/miniforge3/envs/atcs/lib/python3.10/ssl.py:1129\u001B[0m, in \u001B[0;36mSSLSocket.read\u001B[0;34m(self, len, buffer)\u001B[0m\n\u001B[1;32m   1127\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1128\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m buffer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1129\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sslobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1130\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1131\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sslobj\u001B[38;5;241m.\u001B[39mread(\u001B[38;5;28mlen\u001B[39m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We then load the final model checkpoint for the BiLSTMMaxPool. There may be an error that the `embedding.weight` is missing from the checkpoint, but this was done simply to reduce the size of the checkpoints. We set `strict=False` and provide the embedding vectors to the model init function through the kwargs of the `load_from_checkpoint` function.",
   "id": "ae90c41902091a9d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T16:58:09.599215Z",
     "start_time": "2024-04-22T16:58:09.520271Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the model along with the embeddings\n",
    "model = (\n",
    "    NLIClassifier.load_from_checkpoint(\n",
    "        os.path.join(\n",
    "            \"..\",\n",
    "            \"checkpoint\",\n",
    "            \"real_blstmpme_train\",\n",
    "            \"final.ckpt\",\n",
    "        ),\n",
    "        strict=False,\n",
    "        embedding_mat=emb_vecs,\n",
    "    )\n",
    "    .cpu()\n",
    "    .eval()\n",
    ")"
   ],
   "id": "b7f11ded35cbbfca",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We use the same tokenizer that was used to train the model. ",
   "id": "ebfe4552fa9c4c33"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T16:58:09.670210Z",
     "start_time": "2024-04-22T16:58:09.600084Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer = English().tokenizer",
   "id": "8ac9279ade079438",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This function processes the string input, passes it through the model, computes the label, and prints out the final model judgement. ",
   "id": "c9deac9d8ba88f9d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T16:58:09.688481Z",
     "start_time": "2024-04-22T16:58:09.671083Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def predict_and_print(sent_1, sent_2):\n",
    "    inps_1, len_1 = str_to_idxs(sent_1, tokenizer, emb_vocab)\n",
    "    inps_2, len_2 = str_to_idxs(sent_2, tokenizer, emb_vocab)\n",
    "    out = model(inps_1, inps_2, len_1, len_2)\n",
    "    probs = F.softmax(out, dim=-1)\n",
    "    label = torch.argmax(probs, dim=1).unsqueeze(0).detach().item()\n",
    "    print(\n",
    "        f\"\"\"\n",
    "    Premise: \"{sent_1}\"\n",
    "    Hypothesis: \"{sent_2}\"\n",
    "    Model judgement: \"{label_map[label]}\"\n",
    "    \"\"\"\n",
    "    )"
   ],
   "id": "3c84f50d804ebecb",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T16:58:09.718460Z",
     "start_time": "2024-04-22T16:58:09.689207Z"
    }
   },
   "cell_type": "code",
   "source": "predict_and_print(\"Two men sitting in the sun\", \"Nobody is sitting in the shade\")",
   "id": "a56f478cc4580582",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Premise: \"Two men sitting in the sun\"\n",
      "    Hypothesis: \"Nobody is sitting in the shade\"\n",
      "    Model judgement: \"contradiction\"\n",
      "    \n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T16:58:09.745063Z",
     "start_time": "2024-04-22T16:58:09.719413Z"
    }
   },
   "cell_type": "code",
   "source": "predict_and_print(\"A man is walking a dog\", \"No cat is outside\")",
   "id": "ec314d988a41805a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Premise: \"A man is walking a dog\"\n",
      "    Hypothesis: \"No cat is outside\"\n",
      "    Model judgement: \"contradiction\"\n",
      "    \n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Results analysis\n",
    "\n",
    "The examples above are judged as contradictions by the model even though they should be judged as neutral. We can speculate a few reasons why this happens. In the first case, we have a double negative. This may confuse the model. It also required the model to understand the difference between the terms \"sun\" and \"shade\", and it may not have created a very robust understanding of these terms during its training, if these were not present in the training data. In the second case we have the term \"No cat is outside\". The model may not be paying enough attention to the word \"No\", thinking that the the contradiction lies in the fact that both sentences are referring to the same object that is outside, but one is referring to it as a dog, and the other as a cat. "
   ],
   "id": "ba4400d39d10a95f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "595953d7939fb8f9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
